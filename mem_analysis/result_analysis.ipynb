{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed-source LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2717"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel('results/closedsource_sent_responses.xlsx')\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1838"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtered id list from google_filtered_id.txt\n",
    "with open('dataset/google_filtered_ids.txt', 'r') as file:\n",
    "    id_list = file.read().splitlines()\n",
    "\n",
    "#filter df by id_list\n",
    "df_filtered = df[df['ID'].isin(id_list)]\n",
    "df_filtered.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUGE-L Score Analysis by Category:\n",
      "======================================================================================================================================================\n",
      "Category                          gpt-4o-mini                  gemini-1.0-pro           claude-3-haiku-20240307              command-r           \n",
      "                          0.83  0.85  0.9   0.91  0.95  1.0   0.83  0.85  0.9   0.91  0.95  1.0   0.83  0.85  0.9   0.91  0.95  1.0   0.83  0.85  0.9   0.91  0.95  1.0  \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "business & finance         0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "education                  15    7     2     2     0     0     23    17    7     5     2     0     24    15    7     7     2     0     8     5     0     0     0     0   \n",
      "food & drink               5     4     3     2     0     0     6     4     2     2     0     0     6     5     4     2     0     0     3     2     0     0     0     0   \n",
      "movies                     6     3     1     1     1     0     15    12    4     3     1     1     7     5     0     0     0     0     3     1     0     0     0     0   \n",
      "music and audio            0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
      "news and politics          19    12    4     1     0     0     28    22    8     7     4     0     24    19    6     5     1     0     6     3     2     2     1     0   \n",
      "style & fashion            6     4     0     0     0     0     6     6     3     3     0     0     6     4     0     0     0     0     5     4     2     1     0     0   \n",
      "television                 5     5     2     2     2     0     12    9     8     7     3     1     8     5     2     2     1     0     4     4     0     0     0     0   \n",
      "video gaming               9     7     2     1     0     0     22    20    9     7     1     0     20    15    4     3     1     1     4     3     1     1     0     0   \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Overall                    65    42    14    9     3     0    112    90    41    34    11    2     95    68    23    19    5     1     33    22    5     4     1     0   \n",
      "======================================================================================================================================================\n",
      "\n",
      "Total unique sentences with score >= 0.85 across all models: 139\n"
     ]
    }
   ],
   "source": [
    "# Define categories (assuming you have a 'category' column in your DataFrame)\n",
    "categories = ['business & finance', 'education', 'food & drink', 'movies',\n",
    "             'music and audio', 'news and politics', 'style & fashion',\n",
    "             'television', 'video gaming']\n",
    "# categories = ['News and Politics']\n",
    "\n",
    "# Define models to analyze\n",
    "models = ['gpt-4o-mini', 'gemini-1.0-pro', \n",
    "         'claude-3-haiku-20240307', 'command-r']\n",
    "\n",
    "# Define thresholds\n",
    "thresholds = [0.83, 0.85, 0.9, 0.91, 0.95, 1.0]\n",
    "\n",
    "# Print header\n",
    "print(\"\\nROUGE-L Score Analysis by Category:\")\n",
    "print(\"=\" * 150)\n",
    "\n",
    "# Print model headers with proper spacing\n",
    "header = f\"{'Category':<25}\"\n",
    "for model in models:\n",
    "    header += f\"{model:^30}\"\n",
    "print(header)\n",
    "\n",
    "# Print threshold headers\n",
    "threshold_header = \" \" * 25\n",
    "for model in models:\n",
    "    for threshold in thresholds:\n",
    "        threshold_header += f\"{threshold:^6}\"\n",
    "print(threshold_header)\n",
    "\n",
    "print(\"-\" * 150)\n",
    "\n",
    "# Calculate and print results for each category\n",
    "overall_results = {model: {'counts': {threshold: 0 for threshold in thresholds}} for model in models}\n",
    "\n",
    "# Track unique sentences with scores above 0.85 for any model\n",
    "sentences_above_threshold = set()\n",
    "\n",
    "for category in categories:\n",
    "    category_df = df_filtered[df_filtered['category'] == category]\n",
    "    line = f\"{category:<25}\"\n",
    "    \n",
    "    for model in models:\n",
    "        rouge_scores = category_df[f'{model}_rouge_l']\n",
    "        counts = {\n",
    "            threshold: sum(1 for score in rouge_scores if score >= threshold)\n",
    "            for threshold in thresholds\n",
    "        }\n",
    "        \n",
    "        # Update overall counts\n",
    "        for threshold in thresholds:\n",
    "            overall_results[model]['counts'][threshold] += counts[threshold]\n",
    "            \n",
    "        # Track sentences above 0.85\n",
    "        sentences_above_085 = category_df[rouge_scores >= 0.85]['context_sentence']\n",
    "        sentences_above_threshold.update(sentences_above_085)\n",
    "        \n",
    "        # Format counts with proper spacing\n",
    "        for threshold in thresholds:\n",
    "            line += f\"{counts[threshold]:^6}\"\n",
    "    print(line)\n",
    "\n",
    "# Print overall results\n",
    "print(\"-\" * 150)\n",
    "line = \"Overall\".ljust(25)\n",
    "for model in models:\n",
    "    total_counts = overall_results[model]['counts']\n",
    "    for threshold in thresholds:\n",
    "        line += f\"{total_counts[threshold]:^6}\"\n",
    "print(line)\n",
    "print(\"=\" * 150)\n",
    "\n",
    "# Print total unique sentences above 0.85\n",
    "print(f\"\\nTotal unique sentences with score >= 0.85 across all models: {len(sentences_above_threshold)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       news and politics\n",
       "1       news and politics\n",
       "2       news and politics\n",
       "3       news and politics\n",
       "4       news and politics\n",
       "              ...        \n",
       "2712      style & fashion\n",
       "2713      style & fashion\n",
       "2714      style & fashion\n",
       "2715      style & fashion\n",
       "2716      style & fashion\n",
       "Name: category, Length: 2717, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open-source LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE 8: Comparison of ROUGE-L similarity scores across LLMs in disallowed categories\n",
      "------------------------------------------------------------------------\n",
      "                        GPT-2-XL(1.5B)   Llama-3.1-8B    Gemma-2-9B\n",
      "Category                --------------   --------------  ---------------\n",
      "                        >=0.83  >=0.90   >=0.83  >=0.90  >=0.83  >=0.90\n",
      "------------------------------------------------------------------------\n",
      "Business & Finance        0       0        3       1       2       2\n",
      "Education                 6       4        4       1       5       1\n",
      "Food & Drink              0       0        2       1       7       4\n",
      "Movies                    0       0        3       0       6       1\n",
      "Music and Audio           0       0        0       0       0       0\n",
      "News and Politics         4       0        4       0       8       4\n",
      "Style & Fashion           0       0        4       0       5       1\n",
      "Television                1       0        3       0       6       3\n",
      "Video Gaming              1       0        3       0       6       1\n",
      "------------------------------------------------------------------------\n",
      "Overall                   12      4        26      3       45      17\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "import json\n",
    "import os\n",
    "\n",
    "def readjson(filepath):\n",
    "    data = {}\n",
    "    with open(filepath,'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def readFile(filePath):\n",
    "    lines = []\n",
    "    with open(filePath,'r',encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "\n",
    "def getWebsiteCategoryResult(filepath, threshold):\n",
    "\n",
    "    alldatas = readjson(filepath)\n",
    "    allresult = {}\n",
    "    allresult['business and finance'] = 0\n",
    "    allresult['education'] = 0\n",
    "    allresult['food & drink'] = 0\n",
    "    allresult['movies'] = 0\n",
    "    allresult['music and audio'] = 0\n",
    "    allresult['news and politics'] = 0\n",
    "    allresult['style & fashion'] = 0\n",
    "    allresult['television'] = 0\n",
    "    allresult['video gaming'] = 0\n",
    "    for website in alldatas:\n",
    "        datas = alldatas[website]\n",
    "        for filename in datas:\n",
    "            data = datas[filename]\n",
    "            category = data['category']\n",
    "            if data['similarity'] >= threshold:\n",
    "                allresult[category] = allresult[category] + 1\n",
    "    total = 0\n",
    "    for category in allresult:\n",
    "        total = total + allresult[category]\n",
    "    allresult['total'] = total\n",
    "    return allresult\n",
    "\n",
    "def forTable8():\n",
    "    allDatasGPT09 = getWebsiteCategoryResult('./results/result_gpt.json',0.9)\n",
    "    allDatasGPT83 = getWebsiteCategoryResult('./results/result_gpt.json',0.83)\n",
    "    allDatasLlama09 = getWebsiteCategoryResult('./results/result_llama.json',0.9)\n",
    "    allDatasLlama83 = getWebsiteCategoryResult('./results/result_llama.json',0.83)\n",
    "    allDatasGemma09 = getWebsiteCategoryResult('./results/result_gemma.json',0.9)\n",
    "    allDatasGemma83 = getWebsiteCategoryResult('./results/result_gemma.json',0.83)\n",
    "\n",
    "    print('TABLE 8: Comparison of ROUGE-L similarity scores across LLMs in disallowed categories')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('                        GPT-2-XL(1.5B)   Llama-3.1-8B    Gemma-2-9B')\n",
    "    print('Category                --------------   --------------  ---------------')\n",
    "    print('                        >=0.83  >=0.90   >=0.83  >=0.90  >=0.83  >=0.90')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Business & Finance        %d       %d        %d       %d       %d       %d'%(allDatasGPT83['business and finance'],allDatasGPT09['business and finance'],allDatasLlama83['business and finance'],allDatasLlama09['business and finance'],allDatasGemma83['business and finance'],allDatasGemma09['business and finance']))\n",
    "    print('Education                 %d       %d        %d       %d       %d       %d'%(allDatasGPT83['education'],allDatasGPT09['education'],allDatasLlama83['education'],allDatasLlama09['education'],allDatasGemma83['education'],allDatasGemma09['education']))\n",
    "    print('Food & Drink              %d       %d        %d       %d       %d       %d'%(allDatasGPT83['food & drink'],allDatasGPT09['food & drink'],allDatasLlama83['food & drink'],allDatasLlama09['food & drink'],allDatasGemma83['food & drink'],allDatasGemma09['food & drink']))\n",
    "    print('Movies                    %d       %d        %d       %d       %d       %d'%(allDatasGPT83['movies'],allDatasGPT09['movies'],allDatasLlama83['movies'],allDatasLlama09['movies'],allDatasGemma83['movies'],allDatasGemma09['movies']))\n",
    "    print('Music and Audio           %d       %d        %d       %d       %d       %d'%(allDatasGPT83['music and audio'],allDatasGPT09['music and audio'],allDatasLlama83['music and audio'],allDatasLlama09['music and audio'],allDatasGemma83['music and audio'],allDatasGemma09['music and audio']))\n",
    "    print('News and Politics         %d       %d        %d       %d       %d       %d'%(allDatasGPT83['news and politics'],allDatasGPT09['news and politics'],allDatasLlama83['news and politics'],allDatasLlama09['news and politics'],allDatasGemma83['news and politics'],allDatasGemma09['news and politics']))\n",
    "    print('Style & Fashion           %d       %d        %d       %d       %d       %d'%(allDatasGPT83['style & fashion'],allDatasGPT09['style & fashion'],allDatasLlama83['style & fashion'],allDatasLlama09['style & fashion'],allDatasGemma83['style & fashion'],allDatasGemma09['style & fashion']))\n",
    "    print('Television                %d       %d        %d       %d       %d       %d'%(allDatasGPT83['television'],allDatasGPT09['television'],allDatasLlama83['television'],allDatasLlama09['television'],allDatasGemma83['television'],allDatasGemma09['television']))\n",
    "    print('Video Gaming              %d       %d        %d       %d       %d       %d'%(allDatasGPT83['video gaming'],allDatasGPT09['video gaming'],allDatasLlama83['video gaming'],allDatasLlama09['video gaming'],allDatasGemma83['video gaming'],allDatasGemma09['video gaming']))\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Overall                   %d      %d        %d      %d       %d      %d'%(allDatasGPT83['total'],allDatasGPT09['total'],allDatasLlama83['total'],allDatasLlama09['total'],allDatasGemma83['total'],allDatasGemma09['total']))\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "forTable8()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmbot_compliance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
