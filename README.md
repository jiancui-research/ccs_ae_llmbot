# **The Odyssey of robots.txt Governance: Measuring Compliance Implications of Web Crawling Bots in Large Language Model Services**  

This repository contains the implementation details of our paper titled:  
*"The Odyssey of robots.txt Governance: Measuring Compliance Implications of Web Crawling Bots in Large Language Model Services."*  

## ğŸ“‹ **Artifact Overview**

This artifact validates the following claims from our paper:
- **Section 4.2**: Web Publishers' Response to LLM Bots - Awareness and adoption patterns
- **Section 4.2**: Web Publishers' preferences on LLM bots  
- **Section 5.1**: Memorization analysis for open-source and closed-source LLMs
- **Section 5.2**: Case Study: ChatGPT-User behavior analysis

**Total estimated time**: 45-60 human-minutes

## ğŸš€ **Getting Started**

### ğŸ’» **System Requirements**
- **RAM**: 32GB minimum (some notebooks load 18GB files)
- **Storage**: 25GB free space
- **OS**: Windows 10+, macOS 10.15+, Linux Ubuntu 18.04+

---

## ğŸ³ **Option 1: Docker Setup (Recommended)**

### Prerequisites
- Docker Desktop with 32GB+ memory allocation
- 25GB free disk space

### Setup Steps
1. **Configure Docker Memory**: Docker Desktop â†’ Settings â†’ Resources â†’ Memory â†’ Set to 32GB â†’ Apply & Restart
2. **Run Container**:
   ```bash
   docker-compose up --build
   ```
3. **Access JupyterLab**: Open `http://localhost:8888`

**Note**: Data downloads automatically on first startup.

### Troubleshooting
- **Kernel Dying**: Increase Docker memory to 32GB+ in Docker Desktop settings
- **Port 8888 in use**: Change port in `docker-compose.yml`
- **Slow startup**: Normal on first run (downloads 3.9GB data)

---

## ğŸ **Option 2: Local Conda Setup**

### Prerequisites
- Python 3.10+ and Conda installed
- 32GB RAM and 25GB free space

### Setup Steps
1. **Create Environment**:
   ```bash
   conda create -n llmbot_compliance python=3.10
   conda activate llmbot_compliance
   pip install -r requirements.txt
   ```

2. **Download Data**:
   ```bash
   wget "https://drive.google.com/uc?export=download&id=16y_QrENhjra7lCDrRz7yIJqE-bwrGzXr" -O measurement_data.zip
   unzip measurement_data.zip
   ```

### Troubleshooting
- **Kernel**: Use the "llmbot_compliance" jupyter kernel. 


## ğŸ›  **Repository Structure**  

```plaintext
.
â”œâ”€â”€ publisher_response/       # Section 4.2 "Awareness of LLM bots and the adoption of `robots.txt`"
â”‚   â”œâ”€â”€ response_times.ipynb
â”‚   â”œâ”€â”€ llm_release_before_after_count.ipynb
â”‚   â””â”€â”€ news_domains_bot_analysis.ipynb
â”œâ”€â”€ bot_preference/           # Section 4.2 on "LLM bots' preferences"
â”‚   â”œâ”€â”€ calculate_favorability.py
â”‚   â”œâ”€â”€ favoribility_scores.ipynb
â”‚   â””â”€â”€ inconsistency_analysis.ipynb
â”œâ”€â”€ mem_analysis/             # Section 5.1 Compliance and memorization analysis
â”‚   â”œâ”€â”€ opensource_next_sent_gen.py
â”‚   â”œâ”€â”€ closedsource_next_sent_gen.py
â”‚   â””â”€â”€ result_analysis.ipynb
â”œâ”€â”€ chatgpt_casestudy/        # Section 5.2 Case Study: ChatGPT-User
â”‚   â”œâ”€â”€ request_mydomain.py   # send a packet to server
â”‚   â””â”€â”€ accesslog_analysis.py
â”œâ”€â”€ measurement_data/          # Extracted datasets (3.9GB)
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ docker/                    # Docker configuration files
â”‚   â”œâ”€â”€ Dockerfile             # Docker container configuration
â”‚   â””â”€â”€ .dockerignore          # Docker ignore file
â”œâ”€â”€ scripts/                   # Utility scripts
â”‚   â”œâ”€â”€ startup.sh             # Container startup script
â”‚   â””â”€â”€ bash_setup.sh          # Enhanced terminal configuration
â”œâ”€â”€ docker-compose.yml         # Symlink to docker/docker-compose.yml (for convenience)
â””â”€â”€ README_CCS_AE.md          # This artifact documentation
```

## ğŸ“ˆ **Validating Paper Claims**

### Section 4.2 Claims:
- **Table 3**: Generated by running `publisher_response/response_times.ipynb` - reproduces publisher response time analysis
- **Table 4**: Generated by running `bot_preference/inconsistency_analysis.ipynb` - analyzes inconsistencies in bot treatment across publishers

(Optinal)
- **Figure 4**: Generated by running `publisher_response/llm_release_before_after_count.ipynb` - shows robots.txt adoption trends before and after LLM release
- **Figure 5**: Generated by running `publisher_response/news_domains_bot_analysis.ipynb` - shows LLM bot inclusion changes over time for major news domains
- **Figure 6**: Generated by running `bot_preference/favoribility_scores.ipynb` - shows bot preference scores and favorability analysis
- **Figure 7**: Generated by running `bot_preference/web_policy_inconsistency.ipynb` - analyzes inconsistencies between website policy and robots.txt

### Section 5.1 Claims:
- **Table 6**: `mem_analysis/result_analysis.ipynb` summarizes the memorization analysis of LLMs using pre-computed data in the `results/` directory.

#### Optional: Generate Raw Results
If you want to regenerate the raw data files yourself, you can use the following scripts:
- `mem_analysis/opensource_next_sent_gen.py` - for open-source LLMs
- `mem_analysis/closedsource_next_sent_gen.py` - for closed-source LLMs

**Requirements for regenerating results:**

**For closed-source LLMs:** You need to configure API keys from respective LLM vendor websites.

**For open-source LLMs:** You need machines with specific GPU requirements:
- **GPT variants**: â‰¥8GB VRAM  
- **LLaMA & Gemma variants**: â‰¥40GB VRAM
- **Storage**: â‰¥200GB free space
- **Runtime**: ~12 hours (GPT-only) or ~1 week (full run)

ğŸ“‹ **Detailed setup instructions**: See `mem_analysis/mem_analysis_readme.md`


### Section 5.2 Claims:
- **Case Study**: Generated by running `chatgpt_casestudy/accesslog_analysis.py`. You can find a table related to ChatGPT-User, which summarizes the access log of ChatGPT-User. The analysis identifies that ChatGPT-User accessed the `/better/` path, which is disallowed by robots.txt, demonstrating non-compliant behavior.

